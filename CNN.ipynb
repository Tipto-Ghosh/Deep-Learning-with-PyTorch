{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cb883ae-d695-49ac-b294-26484523d9ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dfc8cc3-6ca9-41b1-a464-e0786168b8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87a55034-f962-4adb-9b36-722cbacbcc6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x26dec3b3a70>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set random seed for reproducibility \n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79a99980-c174-4517-aba0-9e1f17a93821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>pixel11</th>\n",
       "      <th>pixel12</th>\n",
       "      <th>pixel13</th>\n",
       "      <th>pixel14</th>\n",
       "      <th>pixel15</th>\n",
       "      <th>pixel16</th>\n",
       "      <th>pixel17</th>\n",
       "      <th>pixel18</th>\n",
       "      <th>pixel19</th>\n",
       "      <th>pixel20</th>\n",
       "      <th>pixel21</th>\n",
       "      <th>pixel22</th>\n",
       "      <th>pixel23</th>\n",
       "      <th>pixel24</th>\n",
       "      <th>pixel25</th>\n",
       "      <th>pixel26</th>\n",
       "      <th>pixel27</th>\n",
       "      <th>pixel28</th>\n",
       "      <th>pixel29</th>\n",
       "      <th>pixel30</th>\n",
       "      <th>pixel31</th>\n",
       "      <th>pixel32</th>\n",
       "      <th>pixel33</th>\n",
       "      <th>pixel34</th>\n",
       "      <th>pixel35</th>\n",
       "      <th>pixel36</th>\n",
       "      <th>pixel37</th>\n",
       "      <th>pixel38</th>\n",
       "      <th>pixel39</th>\n",
       "      <th>pixel40</th>\n",
       "      <th>pixel41</th>\n",
       "      <th>pixel42</th>\n",
       "      <th>pixel43</th>\n",
       "      <th>pixel44</th>\n",
       "      <th>pixel45</th>\n",
       "      <th>pixel46</th>\n",
       "      <th>pixel47</th>\n",
       "      <th>pixel48</th>\n",
       "      <th>pixel49</th>\n",
       "      <th>pixel50</th>\n",
       "      <th>pixel51</th>\n",
       "      <th>pixel52</th>\n",
       "      <th>pixel53</th>\n",
       "      <th>pixel54</th>\n",
       "      <th>pixel55</th>\n",
       "      <th>pixel56</th>\n",
       "      <th>pixel57</th>\n",
       "      <th>pixel58</th>\n",
       "      <th>pixel59</th>\n",
       "      <th>pixel60</th>\n",
       "      <th>pixel61</th>\n",
       "      <th>pixel62</th>\n",
       "      <th>pixel63</th>\n",
       "      <th>pixel64</th>\n",
       "      <th>pixel65</th>\n",
       "      <th>pixel66</th>\n",
       "      <th>pixel67</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel717</th>\n",
       "      <th>pixel718</th>\n",
       "      <th>pixel719</th>\n",
       "      <th>pixel720</th>\n",
       "      <th>pixel721</th>\n",
       "      <th>pixel722</th>\n",
       "      <th>pixel723</th>\n",
       "      <th>pixel724</th>\n",
       "      <th>pixel725</th>\n",
       "      <th>pixel726</th>\n",
       "      <th>pixel727</th>\n",
       "      <th>pixel728</th>\n",
       "      <th>pixel729</th>\n",
       "      <th>pixel730</th>\n",
       "      <th>pixel731</th>\n",
       "      <th>pixel732</th>\n",
       "      <th>pixel733</th>\n",
       "      <th>pixel734</th>\n",
       "      <th>pixel735</th>\n",
       "      <th>pixel736</th>\n",
       "      <th>pixel737</th>\n",
       "      <th>pixel738</th>\n",
       "      <th>pixel739</th>\n",
       "      <th>pixel740</th>\n",
       "      <th>pixel741</th>\n",
       "      <th>pixel742</th>\n",
       "      <th>pixel743</th>\n",
       "      <th>pixel744</th>\n",
       "      <th>pixel745</th>\n",
       "      <th>pixel746</th>\n",
       "      <th>pixel747</th>\n",
       "      <th>pixel748</th>\n",
       "      <th>pixel749</th>\n",
       "      <th>pixel750</th>\n",
       "      <th>pixel751</th>\n",
       "      <th>pixel752</th>\n",
       "      <th>pixel753</th>\n",
       "      <th>pixel754</th>\n",
       "      <th>pixel755</th>\n",
       "      <th>pixel756</th>\n",
       "      <th>pixel757</th>\n",
       "      <th>pixel758</th>\n",
       "      <th>pixel759</th>\n",
       "      <th>pixel760</th>\n",
       "      <th>pixel761</th>\n",
       "      <th>pixel762</th>\n",
       "      <th>pixel763</th>\n",
       "      <th>pixel764</th>\n",
       "      <th>pixel765</th>\n",
       "      <th>pixel766</th>\n",
       "      <th>pixel767</th>\n",
       "      <th>pixel768</th>\n",
       "      <th>pixel769</th>\n",
       "      <th>pixel770</th>\n",
       "      <th>pixel771</th>\n",
       "      <th>pixel772</th>\n",
       "      <th>pixel773</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>80</td>\n",
       "      <td>24</td>\n",
       "      <td>224</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>226</td>\n",
       "      <td>224</td>\n",
       "      <td>237</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>109</td>\n",
       "      <td>199</td>\n",
       "      <td>243</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>251</td>\n",
       "      <td>242</td>\n",
       "      <td>236</td>\n",
       "      <td>230</td>\n",
       "      <td>246</td>\n",
       "      <td>228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>210</td>\n",
       "      <td>228</td>\n",
       "      <td>228</td>\n",
       "      <td>233</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>81</td>\n",
       "      <td>133</td>\n",
       "      <td>184</td>\n",
       "      <td>201</td>\n",
       "      <td>190</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>205</td>\n",
       "      <td>196</td>\n",
       "      <td>213</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>117</td>\n",
       "      <td>34</td>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>117</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>144</td>\n",
       "      <td>152</td>\n",
       "      <td>202</td>\n",
       "      <td>213</td>\n",
       "      <td>210</td>\n",
       "      <td>205</td>\n",
       "      <td>204</td>\n",
       "      <td>221</td>\n",
       "      <td>157</td>\n",
       "      <td>172</td>\n",
       "      <td>131</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>152</td>\n",
       "      <td>140</td>\n",
       "      <td>...</td>\n",
       "      <td>156</td>\n",
       "      <td>153</td>\n",
       "      <td>156</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>157</td>\n",
       "      <td>148</td>\n",
       "      <td>155</td>\n",
       "      <td>146</td>\n",
       "      <td>151</td>\n",
       "      <td>149</td>\n",
       "      <td>152</td>\n",
       "      <td>154</td>\n",
       "      <td>157</td>\n",
       "      <td>158</td>\n",
       "      <td>161</td>\n",
       "      <td>148</td>\n",
       "      <td>159</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>143</td>\n",
       "      <td>143</td>\n",
       "      <td>148</td>\n",
       "      <td>146</td>\n",
       "      <td>152</td>\n",
       "      <td>152</td>\n",
       "      <td>148</td>\n",
       "      <td>148</td>\n",
       "      <td>147</td>\n",
       "      <td>145</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>114</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>136</td>\n",
       "      <td>31</td>\n",
       "      <td>136</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>212</td>\n",
       "      <td>215</td>\n",
       "      <td>213</td>\n",
       "      <td>209</td>\n",
       "      <td>207</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>199</td>\n",
       "      <td>197</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>164</td>\n",
       "      <td>152</td>\n",
       "      <td>138</td>\n",
       "      <td>152</td>\n",
       "      <td>160</td>\n",
       "      <td>152</td>\n",
       "      <td>162</td>\n",
       "      <td>144</td>\n",
       "      <td>208</td>\n",
       "      <td>181</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>69</td>\n",
       "      <td>88</td>\n",
       "      <td>86</td>\n",
       "      <td>94</td>\n",
       "      <td>106</td>\n",
       "      <td>114</td>\n",
       "      <td>118</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>145</td>\n",
       "      <td>114</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>132</td>\n",
       "      <td>134</td>\n",
       "      <td>151</td>\n",
       "      <td>170</td>\n",
       "      <td>188</td>\n",
       "      <td>209</td>\n",
       "      <td>230</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>134</td>\n",
       "      <td>155</td>\n",
       "      <td>178</td>\n",
       "      <td>149</td>\n",
       "      <td>163</td>\n",
       "      <td>165</td>\n",
       "      <td>138</td>\n",
       "      <td>147</td>\n",
       "      <td>170</td>\n",
       "      <td>149</td>\n",
       "      <td>134</td>\n",
       "      <td>165</td>\n",
       "      <td>153</td>\n",
       "      <td>155</td>\n",
       "      <td>134</td>\n",
       "      <td>143</td>\n",
       "      <td>172</td>\n",
       "      <td>215</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>190</td>\n",
       "      <td>178</td>\n",
       "      <td>194</td>\n",
       "      <td>209</td>\n",
       "      <td>211</td>\n",
       "      <td>209</td>\n",
       "      <td>205</td>\n",
       "      <td>211</td>\n",
       "      <td>215</td>\n",
       "      <td>213</td>\n",
       "      <td>217</td>\n",
       "      <td>225</td>\n",
       "      <td>228</td>\n",
       "      <td>213</td>\n",
       "      <td>203</td>\n",
       "      <td>174</td>\n",
       "      <td>151</td>\n",
       "      <td>188</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  ...  pixel778  pixel779  pixel780  pixel781  pixel782  pixel783  pixel784\n",
       "0      9       0       0       0       0       0       0  ...        50       205       196       213       165         0         0\n",
       "1      7       0       0       0       0       0       0  ...         0         0         0         0         0         0         0\n",
       "2      0       0       0       0       0       0       1  ...        21         0         3         0         0         0         0\n",
       "3      8       0       0       0       0       0       0  ...         0         0         0         0         0         0         0\n",
       "4      8       0       0       0       0       0       0  ...       151       188        10         0         0         0         0\n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"fmnist_small.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a9890d1-0ed4-4a05-b38e-17748a69c7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 785)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "611e14fa-f9b3-4993-895b-31b65150b201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate target andf input features\n",
    "X = df.drop(columns = ['label'] , axis = 1)\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34e02fef-6644-457b-a811-068e66bec3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the train test split \n",
    "X_train , X_test , y_train , y_test = train_test_split(X , y , test_size = 0.2 , random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4d2cb63-9e22-4e83-927f-a2bac4219f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the pixcel values\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76effe54-cc62-45ee-8d00-39d70513410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all these into numpy array \n",
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy() \n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0210ef9-6488-4333-a743-9a95977a0f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset): \n",
    "    def __init__(self , features , labels):\n",
    "        # convert the input numpy array into tensor and also from 1D to 2D\n",
    "        # reshape(batch_size = -1[place holder] , number of channel , Height , Width)\n",
    "        self.features = torch.tensor(features , dtype = torch.float32).reshape(-1 , 1 , 28 , 28)\n",
    "        self.labels = torch.tensor(labels , dtype = torch.long)\n",
    "    \n",
    "    def __len__(self): \n",
    "        return len(self.features) \n",
    "    \n",
    "    def __getitem__(self , index): \n",
    "        return self.features[index] , self.labels[index] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc79bfc9-24f4-466a-bf0c-056ad3192dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(X_train , y_train)\n",
    "test_dataset = CustomDataset(X_test , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fd84a4d-8bbf-4ea7-81a1-45c062102e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the dataloader \n",
    "train_data_loader = DataLoader(\n",
    "    dataset = train_dataset, \n",
    "    batch_size = 32, \n",
    "    shuffle = True,\n",
    "    pin_memory = True\n",
    ")\n",
    "\n",
    "test_data_loader = DataLoader(\n",
    "    dataset = test_dataset, \n",
    "    batch_size = 32, \n",
    "    pin_memory = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf0f91d4-1367-4e23-980b-2d0e20a8e18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN \n",
    "class MyCNN(nn.Module): \n",
    "    def __init__(self , input_channels): \n",
    "        super().__init__()\n",
    "        # CNN has 2 parts: 1. Feature Extraction Layers , 2. FC layers\n",
    "        self.feature_extraction = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = input_channels , out_channels = 32 , kernel_size = 3 , padding = 'same'),\n",
    "            nn.BatchNorm2d(num_features = 32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2 , stride = 2),\n",
    "\n",
    "            nn.Conv2d(in_channels = 32 , out_channels = 64 , kernel_size = 3 , padding = 'same'),\n",
    "            nn.BatchNorm2d(num_features = 64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2 , stride = 2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            # flatten layer \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features = 64*7*7 , out_features = 128),\n",
    "            nn.ReLU(), \n",
    "            nn.Dropout(p = 0.4),\n",
    "\n",
    "            nn.Linear(in_features = 128 , out_features = 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p = 0.4),\n",
    "\n",
    "            nn.Linear(64 , 10)\n",
    "        )\n",
    "\n",
    "    def forward(self , x): \n",
    "        x = self.feature_extraction(x)\n",
    "        x = self.classifier(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b9e5b32-a2b5-451d-b490-b43e965e36c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3435661c-980d-408a-aaa3-1d4e465e3139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyCNN(\n",
       "  (feature_extraction): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=3136, out_features=128, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.4, inplace=False)\n",
       "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Dropout(p=0.4, inplace=False)\n",
       "    (7): Linear(in_features=64, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyCNN(input_channels = 1)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78c785e1-f846-4279-8c29-ff4ca15125a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters() , lr = learning_rate , weight_decay = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16a884ef-69d2-4f92-9273-113c2ac7a052",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Loss: 1.6670839246114095\n",
      "Epoch: 2 | Loss: 0.9905066915353139\n",
      "Epoch: 3 | Loss: 0.8119085093339284\n",
      "Epoch: 4 | Loss: 0.7214896335204443\n",
      "Epoch: 5 | Loss: 0.6658143840233485\n",
      "Epoch: 6 | Loss: 0.6162446649869283\n",
      "Epoch: 7 | Loss: 0.572268722653389\n",
      "Epoch: 8 | Loss: 0.5459293020764987\n",
      "Epoch: 9 | Loss: 0.5194110749165217\n",
      "Epoch: 10 | Loss: 0.48124695946772894\n",
      "Epoch: 11 | Loss: 0.4710633987188339\n",
      "Epoch: 12 | Loss: 0.4547058030962944\n",
      "Epoch: 13 | Loss: 0.42825803369283677\n",
      "Epoch: 14 | Loss: 0.403708356320858\n",
      "Epoch: 15 | Loss: 0.3856340597569943\n",
      "Epoch: 16 | Loss: 0.36812804996967313\n",
      "Epoch: 17 | Loss: 0.35010647306839626\n",
      "Epoch: 18 | Loss: 0.32722114597757657\n",
      "Epoch: 19 | Loss: 0.3223238901297251\n",
      "Epoch: 20 | Loss: 0.3017922617991765\n",
      "Epoch: 21 | Loss: 0.284533609499534\n",
      "Epoch: 22 | Loss: 0.26595493465662\n",
      "Epoch: 23 | Loss: 0.27313355877995493\n",
      "Epoch: 24 | Loss: 0.2538362294435501\n",
      "Epoch: 25 | Loss: 0.240575590133667\n",
      "Epoch: 26 | Loss: 0.23100154941280682\n",
      "Epoch: 27 | Loss: 0.21541160581012567\n",
      "Epoch: 28 | Loss: 0.21517249142130215\n",
      "Epoch: 29 | Loss: 0.21329348931709927\n",
      "Epoch: 30 | Loss: 0.19230002691348394\n",
      "Epoch: 31 | Loss: 0.18775485416253407\n",
      "Epoch: 32 | Loss: 0.17950356336931386\n",
      "Epoch: 33 | Loss: 0.17163174188385408\n",
      "Epoch: 34 | Loss: 0.17605758521705867\n",
      "Epoch: 35 | Loss: 0.14635637829701106\n",
      "Epoch: 36 | Loss: 0.14477378758291404\n",
      "Epoch: 37 | Loss: 0.14495487152288358\n",
      "Epoch: 38 | Loss: 0.13689067670454583\n",
      "Epoch: 39 | Loss: 0.12271043766910832\n",
      "Epoch: 40 | Loss: 0.1294417833040158\n",
      "Epoch: 41 | Loss: 0.11919193626071016\n",
      "Epoch: 42 | Loss: 0.10771542840947708\n",
      "Epoch: 43 | Loss: 0.10978310981765389\n",
      "Epoch: 44 | Loss: 0.10421482096115749\n",
      "Epoch: 45 | Loss: 0.10313799943774939\n",
      "Epoch: 46 | Loss: 0.09327525595823924\n",
      "Epoch: 47 | Loss: 0.09029523257166147\n",
      "Epoch: 48 | Loss: 0.08201265923057993\n",
      "Epoch: 49 | Loss: 0.08770726362864177\n",
      "Epoch: 50 | Loss: 0.08053405001138647\n",
      "Epoch: 51 | Loss: 0.07025768886009852\n",
      "Epoch: 52 | Loss: 0.07073351971261824\n",
      "Epoch: 53 | Loss: 0.05099536196639141\n",
      "Epoch: 54 | Loss: 0.0643312640239795\n",
      "Epoch: 55 | Loss: 0.060833178252602614\n",
      "Epoch: 56 | Loss: 0.06449472945183515\n",
      "Epoch: 57 | Loss: 0.057457486890877284\n",
      "Epoch: 58 | Loss: 0.06260704588921119\n",
      "Epoch: 59 | Loss: 0.05531739306170493\n",
      "Epoch: 60 | Loss: 0.04790710645106932\n",
      "Epoch: 61 | Loss: 0.044582959231920544\n",
      "Epoch: 62 | Loss: 0.0443458783471336\n",
      "Epoch: 63 | Loss: 0.039331714459694925\n",
      "Epoch: 64 | Loss: 0.041743423901498315\n",
      "Epoch: 65 | Loss: 0.05480838782154024\n",
      "Epoch: 66 | Loss: 0.03826705956210693\n",
      "Epoch: 67 | Loss: 0.044779910982276\n",
      "Epoch: 68 | Loss: 0.03776274578335385\n",
      "Epoch: 69 | Loss: 0.04452393711893819\n",
      "Epoch: 70 | Loss: 0.03668983633785198\n",
      "Epoch: 71 | Loss: 0.03149272187341315\n",
      "Epoch: 72 | Loss: 0.03282284334379559\n",
      "Epoch: 73 | Loss: 0.030220857878836493\n",
      "Epoch: 74 | Loss: 0.03125321102406209\n",
      "Epoch: 75 | Loss: 0.034492362147818006\n",
      "Epoch: 76 | Loss: 0.047263673472916705\n",
      "Epoch: 77 | Loss: 0.037176720093314845\n",
      "Epoch: 78 | Loss: 0.03576438288825254\n",
      "Epoch: 79 | Loss: 0.030998890354530885\n",
      "Epoch: 80 | Loss: 0.03160515745791296\n",
      "Epoch: 81 | Loss: 0.023610066825834414\n",
      "Epoch: 82 | Loss: 0.02735151812278976\n",
      "Epoch: 83 | Loss: 0.03463399211332823\n",
      "Epoch: 84 | Loss: 0.022923803592566402\n",
      "Epoch: 85 | Loss: 0.031881005465984345\n",
      "Epoch: 86 | Loss: 0.018159214436309412\n",
      "Epoch: 87 | Loss: 0.02468269844306633\n",
      "Epoch: 88 | Loss: 0.019607821995159612\n",
      "Epoch: 89 | Loss: 0.017096874459724253\n",
      "Epoch: 90 | Loss: 0.018645275068314125\n",
      "Epoch: 91 | Loss: 0.02004280469758669\n",
      "Epoch: 92 | Loss: 0.02313539866125211\n",
      "Epoch: 93 | Loss: 0.013449086568046671\n",
      "Epoch: 94 | Loss: 0.0175213533511851\n",
      "Epoch: 95 | Loss: 0.01783649225253612\n",
      "Epoch: 96 | Loss: 0.01749033616390079\n",
      "Epoch: 97 | Loss: 0.016447497636351425\n",
      "Epoch: 98 | Loss: 0.015059978163141446\n",
      "Epoch: 99 | Loss: 0.017729223592129226\n",
      "Epoch: 100 | Loss: 0.025399636241684977\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs): \n",
    "    total_epoch_loss = 0\n",
    "    for batch_features , batch_labels in train_data_loader: \n",
    "        # move the features and labels to GPU \n",
    "        batch_features = batch_features.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "\n",
    "        # forward pass \n",
    "        outputs = model(batch_features)\n",
    "        # calculate loss \n",
    "        loss = criterion(outputs , batch_labels)\n",
    "        total_epoch_loss += loss.item()\n",
    "\n",
    "        # clear grad \n",
    "        optimizer.zero_grad()\n",
    "        # backward \n",
    "        loss.backward()\n",
    "        # update weights and bias \n",
    "        optimizer.step()\n",
    "\n",
    "    avg_epoch_loss = total_epoch_loss / len(train_data_loader)\n",
    "    print(f\"Epoch: {epoch + 1} | Loss: {avg_epoch_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1e266fb-0b6d-4046-8d79-dc51ef06e576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyCNN(\n",
       "  (feature_extraction): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=3136, out_features=128, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.4, inplace=False)\n",
       "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Dropout(p=0.4, inplace=False)\n",
       "    (7): Linear(in_features=64, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5332b40-dd38-4ea7-a63c-1a98841d9f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8733333333333333\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad(): \n",
    "    for batch_features , batch_labels in test_data_loader:\n",
    "        # move the features and labels to GPU \n",
    "        batch_features = batch_features.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "        # forward pass \n",
    "        outputs = model(batch_features)\n",
    "\n",
    "        _ , predicted = torch.max(outputs , 1)\n",
    "        total = total + batch_labels.shape[0]\n",
    "        correct = correct + (predicted == batch_labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy: {correct/total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f189d1a2-2d3e-482e-912d-e8ae4495d08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad(): \n",
    "    for batch_features , batch_labels in train_data_loader:\n",
    "        # move the features and labels to GPU \n",
    "        batch_features = batch_features.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "        # forward pass \n",
    "        outputs = model(batch_features)\n",
    "\n",
    "        _ , predicted = torch.max(outputs , 1)\n",
    "        total = total + batch_labels.shape[0]\n",
    "        correct = correct + (predicted == batch_labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy: {correct/total}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
